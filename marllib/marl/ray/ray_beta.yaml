# ray/rllib config

local_mode: False # True for debug mode only
share_policy: "group" #  individual(separate) / group(division) / all(share)
evaluation_interval: 10 # evaluate model every 10 training iterations
framework: "torch"
num_workers: 1 # thread number
num_gpus: 1 # gpu to use
num_cpus_per_worker: 1 # cpu allocate to each worker
num_gpus_per_worker: 0 # gpu allocate to each worker
checkpoint_freq: 100 # save model every 100 training iterations
checkpoint_end: True # save model at the end of the exp
restore_path: "" # load model path: 1. resume exp 2. rendering policy
stop_iters: 9999999 # stop training at this iteration
stop_timesteps: 2000000 # stop training at this timesteps
stop_reward: 999999 # stop training at this reward
seed: 321 # ray seed
local_dir: "" #  working directory by default