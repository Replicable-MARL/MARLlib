{
  "checkpoints": [
    "{\n  \"trainable_name\": \"COMATrainer\",\n  \"trial_id\": \"8581a_00000\",\n  \"config\": {\n    \"train_batch_size\": 50,\n    \"batch_mode\": \"truncate_episodes\",\n    \"use_gae\": true,\n    \"lambda\": 1.0,\n    \"vf_loss_coeff\": 1.0,\n    \"entropy_coeff\": 0.01,\n    \"lr\": 0.0005,\n    \"model\": {\n      \"custom_model\": \"Centralized_Critic_Model\",\n      \"max_seq_len\": 25,\n      \"custom_model_config\": {\n        \"env\": \"mpe\",\n        \"env_args\": {\n          \"continuous_actions\": false,\n          \"max_cycles\": 25,\n          \"map_name\": \"simple_spread\"\n        },\n        \"mask_flag\": false,\n        \"global_state_flag\": false,\n        \"opp_action_in_cc\": true,\n        \"force_coop\": true,\n        \"local_mode\": false,\n        \"share_policy\": \"all\",\n        \"evaluation_interval\": 50,\n        \"framework\": \"torch\",\n        \"num_workers\": 2,\n        \"num_gpus\": 1,\n        \"num_cpus_per_worker\": 1,\n        \"num_gpus_per_worker\": 0,\n        \"checkpoint_freq\": 100,\n        \"checkpoint_end\": false,\n        \"restore_path\": {\n          \"model_path\": \"\",\n          \"params_path\": \"\"\n        },\n        \"stop_iters\": 9999999,\n        \"stop_timesteps\": 2000000,\n        \"stop_reward\": 999999,\n        \"seed\": 321,\n        \"local_dir\": \"\",\n        \"model_arch_args\": {\n          \"hidden_state_size\": 256,\n          \"core_arch\": \"gru\",\n          \"fc_layer\": 2,\n          \"out_dim_fc_0\": 128,\n          \"out_dim_fc_1\": 64,\n          \"encode_layer\": \"16-16\"\n        },\n        \"algo_args\": {\n          \"use_gae\": true,\n          \"lambda\": 1.0,\n          \"vf_loss_coeff\": 1.0,\n          \"batch_episode\": 2,\n          \"batch_mode\": \"truncate_episodes\",\n          \"lr\": 0.0005,\n          \"entropy_coeff\": 0.01\n        },\n        \"algorithm\": \"coma\",\n        \"space_obs\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059582020000000000008c0f67796d2e7370616365732e64696374948c04446963749493942981947d94288c06737061636573948c0b636f6c6c656374696f6e73948c0b4f726465726564446963749493942952948c036f6273948c0e67796d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994681093948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c065f7368617065944b1285948c036c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289648000000000000000000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c29468128c02663494898887945294284b0368164e4e4e4affffffff4affffffff4b007494624b1285948c014394749452948c046869676894681d289648000000000000000000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8429468214b1285946824749452948c0d626f756e6465645f62656c6f7794681d289612000000000000000101010101010101010101010101010101019468128c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b1285946824749452948c0d626f756e6465645f61626f766594681d289612000000000000000101010101010101010101010101010101019468304b1285946824749452948c0a5f6e705f72616e646f6d944e75627368184e68104e683b4e75622e\"\n        },\n        \"space_act\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059582000000000000008c1367796d2e7370616365732e6469736372657465948c0844697363726574659493942981947d94288c016e944b058c065f736861706594298c056474797065948c056e756d707994680793948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        \"num_agents\": 3,\n        \"episode_limit\": 25,\n        \"policy_mapping_info\": {\n          \"simple_adversary\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_crypto\": {\n            \"description\": \"two team cooperate, one team attack\",\n            \"team_prefix\": [\n              \"eve_\",\n              \"bob_\",\n              \"alice_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_push\": {\n            \"description\": \"one team target on landmark, one team attack\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_tag\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_spread\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_reference\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_world_comm\": {\n            \"description\": \"two team cooperate and attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"leadadversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_speaker_listener\": {\n            \"description\": \"two team cooperate\",\n            \"team_prefix\": [\n              \"speaker_\",\n              \"listener_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          }\n        },\n        \"agent_name_ls\": [\n          \"agent_0\",\n          \"agent_1\",\n          \"agent_2\"\n        ]\n      }\n    },\n    \"seed\": 321,\n    \"env\": \"mpe_simple_spread\",\n    \"num_gpus_per_worker\": 0,\n    \"num_gpus\": 1,\n    \"num_workers\": 2,\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059515000000000000008f94288c0d7368617265645f706f6c69637994902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950c030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b024b004b004b034b014b5b430464015300944e8c0d7368617265645f706f6c696379948694298c086167656e745f6964948c07657069736f6465948c066b77617267739487948c7a2f55736572732f67616f6d696e7175616e2f446f63756d656e74732fe5ada6e4b9a0e8b584e696992f446565702d5265696e666f7263656d656e742d4c6561726e696e672f32303232e7a791e7a094e9a1b9e79bae2f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e7079948c083c6c616d6264613e944b3e4300942929749452947d94288c0b5f5f7061636b6167655f5f948c126d61726c6c69622e6d61726c2e616c676f73948c085f5f6e616d655f5f948c196d61726c6c69622e6d61726c2e616c676f732e72756e5f6363948c085f5f66696c655f5f948c7a2f55736572732f67616f6d696e7175616e2f446f63756d656e74732fe5ada6e4b9a0e8b584e696992f446565702d5265696e666f7263656d656e742d4c6561726e696e672f32303232e7a791e7a094e9a1b9e79bae2f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c1872756e5f63632e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      }\n    },\n    \"framework\": \"torch\",\n    \"evaluation_interval\": 50,\n    \"simple_optimizer\": false\n  },\n  \"local_dir\": \"/Users/gaominquan/Documents/\\u5b66\\u4e60\\u8d44\\u6599/Deep-Reinforcement-Learning/2022\\u79d1\\u7814\\u9879\\u76ee/MARLlib/tests/algorithm/exp_results/coma_gru_simple_spread\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d94286808473ff00000000000006809470000000000000000757d94286808473ff0000000000000680947000000000000000075658c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"episode_reward_mean\": 999999,\n    \"timesteps_total\": 2000000,\n    \"training_iteration\": 2\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"8581a_00000\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"start_time\": null,\n  \"logdir\": \"/Users/gaominquan/Documents/\\u5b66\\u4e60\\u8d44\\u6599/Deep-Reinforcement-Learning/2022\\u79d1\\u7814\\u9879\\u76ee/MARLlib/tests/algorithm/exp_results/coma_gru_simple_spread/COMATrainer_mpe_simple_spread_8581a_00000_0_2023-05-14_20-42-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_to_cloud\": null,\n  \"checkpoint_freq\": 100,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 0,
    "_iteration": 197314,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/Users/gaominquan/Documents/\u5b66\u4e60\u8d44\u6599/Deep-Reinforcement-Learning/2022\u79d1\u7814\u9879\u76ee/MARLlib/tests/algorithm/exp_results/coma_gru_simple_spread",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1684122151.5779562,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-05-14_20-42-31",
    "checkpoint_file": "/Users/gaominquan/Documents/\u5b66\u4e60\u8d44\u6599/Deep-Reinforcement-Learning/2022\u79d1\u7814\u9879\u76ee/MARLlib/tests/algorithm/exp_results/coma_gru_simple_spread/experiment_state-2023-05-14_20-42-31.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1684122151.5779562,
    "timestamp": 1684122412.3326879
  }
}