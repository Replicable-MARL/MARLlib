{
  "actor_lr": 0.0005,
  "batch_mode": "complete_episodes",
  "buffer_size": 1000000,
  "critic_lr": 0.0005,
  "env": "mamujoco_2AgentHalfCheetah",
  "evaluation_interval": 10,
  "framework": "torch",
  "learning_starts": 8000,
  "model": {
    "custom_model_config": {
      "algo_args": {
        "actor_lr": 0.0005,
        "batch_episode": 8,
        "batch_mode": "complete_episodes",
        "buffer_size_episode": 1000,
        "critic_lr": 0.0005,
        "learning_starts_episode": 8,
        "n_step": 1,
        "prioritized_replay": false,
        "smooth_target_policy": false,
        "target_network_update_freq_episode": 1,
        "tau": 0.002,
        "twin_q": false
      },
      "algorithm": "maddpg",
      "env": "mamujoco",
      "env_args": {
        "map_name": "2AgentHalfCheetah"
      },
      "episode_limit": 1000,
      "evaluation_interval": 10,
      "fixed_batch_timesteps": 4000,
      "framework": "torch",
      "global_state_flag": true,
      "local_mode": false,
      "mask_flag": false,
      "model_arch_args": {
        "core_arch": "gru",
        "fc_layer": 1,
        "hidden_state_size": 256,
        "out_dim_fc_0": 128
      },
      "num_agents": 2,
      "num_cpus_per_worker": 1,
      "num_gpus": 1,
      "num_gpus_per_worker": 0,
      "num_workers": 1,
      "opp_action_in_cc": true,
      "policy_mapping_info": {
        "all_scenario": {
          "all_agents_one_policy": true,
          "description": "mamujoco all scenarios",
          "one_agent_one_policy": true,
          "team_prefix": [
            "agent_"
          ]
        }
      },
      "seed": 123,
      "share_policy": "all",
      "space_act": "Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)",
      "space_obs": "Dict(obs:Box([-10000. -10000. -10000. -10000. -10000. -10000. -10000.], [10000. 10000. 10000. 10000. 10000. 10000. 10000.], (7,), float32), state:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100.], (17,), float32))",
      "stop_iters": 9999999,
      "stop_reward": 999999,
      "stop_timesteps": 2000000
    },
    "max_seq_len": 1000
  },
  "multiagent": {
    "policies": "{'shared_policy'}",
    "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7fbe28502840>"
  },
  "n_step": 1,
  "num_gpus": 1,
  "num_gpus_per_worker": 0,
  "num_workers": 1,
  "prioritized_replay": false,
  "simple_optimizer": false,
  "smooth_target_policy": false,
  "target_network_update_freq": 1000,
  "tau": 0.002,
  "train_batch_size": 8,
  "twin_q": false,
  "zero_init_states": true
}